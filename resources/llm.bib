@inproceedings{wendler2024llamas,
  title={Do Llamas work in English? On the latent language of multilingual transformers},
  author={Wendler*, Chris and Veselovsky*, Veniamin and Monea*, Giovanni and West*, Robert},
  booktitle={Proceedings of the Association for Computational Linguistics},
  year={2024}
}

@article{minder2024controllable,
  title={Controllable Context Sensitivity and the Knob Behind It},
  author={Minder*, Julian and Du*, Kevin and Stoehr, Niklas and Monea, Giovanni and Wendler, Chris and West, Robert and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2411.07404},
  year={2024}
}

@inproceedings{dumas2024separating,
  title={Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers},
  author={Dumas*, Cl{\'e}ment and Wendler*, Chris and Veselovsky, Veniamin and Monea, Giovanni and West, Robert},
  booktitle={ICML Mechanistic Interpretability Workshop},
  year={2024}
}

@article{brinkmann2025large,
  title={Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages},
  author={Brinkmann, Jannik and Wendler, Chris and Bartelt, Christian and Mueller, Aaron},
  journal={arXiv preprint arXiv:2501.06346},
  year={2025}
}

@article{veselovsky2025localized,
  title={Localized Cultural Knowledge is Conserved and Controllable in Large Language Models},
  author={Veselovsky*, Veniamin and Argin*, Berke and Stroebl*, Benedikt and Wendler, Chris and West, Robert and Evans, James and Griffiths, Thomas L and Narayanan, Arvind},
  journal={arXiv preprint arXiv:2504.10191},
  year={2025}
}